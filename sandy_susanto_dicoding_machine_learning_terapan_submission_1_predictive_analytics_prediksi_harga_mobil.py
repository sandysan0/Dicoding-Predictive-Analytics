# -*- coding: utf-8 -*-
"""Sandy Susanto - Dicoding - Machine Learning Terapan - Submission 1 : Predictive Analytics - Prediksi Harga Mobil.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-Sr0O2gRfnGk5j2OhGQsJLZTzaFwjvp0

# **Proyek Akhir: Predictive Analysis**

---

## Dicoding Submission
## Machine Learning Terapan

---

Kriteria submission:
- Project merupakan hasil pekerjaan sendiri.
- Project belum pernah digunakan untuk submission kelas Machine Learning di Dicoding dan belum pernah dipublikasikan di platform manapun.
- Dataset yang dipakai merupakan data kuantitatif (minimum 500 sampel data).
- Memberikan **dokumentasi** menggunakan **text cell** pada notebook (.ipynb) untuk menjelaskan **setiap tahapan proyek**.
- Menentukan solusi permasalahan menggunakan pendekatan machine learning atau deep learning dengan memilih salah satu dari penyelesaian berikut:
  - Klasifikasi
  - Regresi
  - Clustering
  - Time series dan forecasting
- Membuat draf laporan proyek machine learning yang menjelaskan alur proyek Anda dari mulai pemilihan domain permasalahan (problem domain), data understanding, data preparation, modeling, hingga tahap evaluasi. Ketentuan draf laporan proyek machine learning dapat Anda lihat pada sub modul berikutnya tentang **Detail Laporan**.

---

Saran:
- Menerapkan Rubrik/Kriteria Penilaian (Tambahan) untuk mendapatkan skala penilaian (bintang) yang lebih tinggi.

---

Tips:
- Menerapkan **Rubrik/Kriteria Penilaian (Tambahan)** untuk mendapatkan skala penilaian (bintang) yang lebih tinggi.
- Anda dapat memilih salah satu proyek dari domain (namun tidak terbatas pada daftar) berikut:
  - Kesehatan
  - Ekonomi dan bisnis
  - Keuangan
  - Pertanian dan peternakan
  - Pendidikan
  - Lingkungan
  - Astronomi
  - Kelautan
  - Sosial
  - Telekomunikasi
  - dsb.

---

Detail penilaian submission:
- **Bintang 1**: Semua ketentuan terpenuhi, tetapi terdapat indikasi plagiat dengan menggunakan proyek orang lain dan hanya mengubah kontennya saja.
- **Bintang 2**: Semua ketentuan terpenuhi, tetapi penulisan kode dan laporan berantakan.
- **Bintang 3**: Semua ketentuan terpenuhi, penulisan kode, dan laporan cukup baik.
- **Bintang 4**: Semua ketentuan terpenuhi, menerapkan minimal tiga (3) kriteria **Rubrik Penilaian Tambahan** pada laporan.
- **Bintang 5**: Semua ketentuan terpenuhi, menerapkan minimal **seluruh kriteria (6) Rubrik Penilaian Tambahan** pada laporan.

---

# Data Diri

- Nama: Sandy Susanto
- E-mail: susantosandy12@gmail.com
- Beasiswa : IDCamp2023

---
---

# **1. *Library Import***
"""

# Commented out IPython magic to ensure Python compatibility.
#Import library
import os
import pandas as pd
import tensorflow as tf
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import RandomForestRegressor

"""*   *Library* [`os`](https://docs.python.org/3/library/os.html) berfungsi untuk berinteraksi dengan sistem operasi. Kegunaan dari *library* ini di antaranya dapat melakukan operasi seperti mengubah direktori kerja, menghapus file, dan membaca variabel lingkungan.
*   *Library* [`pandas`](https://pandas.pydata.org/) merupakan *library* analisis data yang kuat yang menyediakan struktur data seperti DataFrame untuk memudahkan manipulasi dan analisis data. *Library* ini bisa menggunakannya untuk membersihkan, menjelajah, dan memproses dataset.
*   [`Tensorflow`](https://www.tensorflow.org/) adalah *library machine learning* yang dikembangkan oleh Google. Digunakan untuk membuat dan melatih model neural network, yang bisa digunakan dalam berbagai aplikasi seperti pengenalan suara, terjemahan bahasa, dan penglihatan komputer.
*   [`Seaborn`](https://seaborn.pydata.org/) adalah *library* visualisasi data berbasis matplotlib yang menyediakan antarmuka tingkat tinggi untuk menggambar grafik statistik yang menarik dan informatif.
*   [`matplotlib.pyplot`](https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html) adalah modul dalam *library* matplotlib yang menyediakan fungsi untuk membuat berbagai jenis plot dan visualisasi data.
*   [`matplotlib.image`](https://matplotlib.org/stable/api/image_api.html) adalah modul yang digunakan untuk membaca, menulis, dan memanipulasi gambar dalam berbagai format sehingga sangat berguna dengan data visual seperti gambar atau foto.

# **2. *Data Loading***

## 2.1 *Kaggle Credential*

**Menghubungkan environtment** [`Colab`](https://colab.research.google.com/) dengan [Kaggle Dataset](https://kaggle.com/) menggunakan `Kaggle.json` yang didapatkan dari meng-*generate* [Kaggle API](https://www.kaggle.com/docs/api) token.

---
Gunakan `!python` untuk mengecek versi [`pyhton`](https://www.python.org/) di [`Colab`](https://colab.research.google.com/) dan memakai `!gdown` untuk men*download* `Kaggle.json` yang disimpan di [Google Drive](https://drive.google.com/)
"""

#Cek python dulu
!python --version

#Download Kaggle Credential
!pip install -q kaggle
!pip install --upgrade gdown
!gdown 1-78YSIrsevhJCtAsWGp2D6j189CdGP76
file = open("kaggle.json", "r")
data = file.read()
print(data)

"""Membuat *environtment* di `/root` dan mengetest *Kaggle API Command*"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod u=rw,g=,o= ~/.kaggle/kaggle.json
!ls ~/.kaggle
!kaggle datasets list

"""## 2.2 *Dataset Download*

**Mengunduh *dataset***  dari *Kaggle*. *Dataset* yang digunakan adalah [Car Price Prediction Challenge](https://www.kaggle.com/datasets/deepcontractor/car-price-prediction-challenge) dalam bentuk `.csv` ([Comma-separated Values](https://en.wikipedia.org/wiki/Comma-separated_values)).
"""

!kaggle datasets download -d deepcontractor/car-price-prediction-challenge

"""Mengekstrak *file* zip dengan [`zipfile`](https://docs.python.org/3/library/zipfile.html)"""

import zipfile
with zipfile.ZipFile('car-price-prediction-challenge.zip','r') as zip:
  zip.extractall('/content/')

"""**Menampilkan *dataset*** dengan *library* [Pandas](https://pandas.pydata.org/) lalu mengubah formatnya dari CSV menjadi *dataframe*."""

car = pd.read_csv('/content/car_price_prediction.csv')
car

"""## 2.3 *Dataset Preparation*

Menghapus kolom yang tidak ada digunakan karena tidak relevan, sama saja dengan kolom lain, dan tidak menjelaskan apapun, yaitu `ID`, `Levy`, `Manufacturer`, `Model`, dan `Prod. year`
"""

car.drop('ID'          , inplace=True, axis=1)
car.drop('Levy'        , inplace=True, axis=1)
car.drop('Manufacturer', inplace=True, axis=1)
car.drop('Model'       , inplace=True, axis=1)
car.drop('Prod. year'  , inplace=True, axis=1)
car

"""Menghilangkan tulisan 'km' dan mengubah tipe data menjadi `int64` dan `float64` supaya lebih mudah untuk melakukan prediksi"""

car['Price'] = car['Price'].astype('float64')
car['Engine volume'] = car['Engine volume'].str.replace(' Turbo', '').astype('float64')
car['Mileage'] = car['Mileage'].str.replace(' km', '').astype('float64')
car['Cylinders'] = car['Cylinders'].astype('int64')

car

"""Dari *dataset* yang telah dibersihkan, terdapat 19.237 baris data dengan atribut sebanyak 13 kolom.

1. `Price` : Harga jual mobil dalam $
2. `Category` : Kategori mobil, seperti SUV, sedan, hatchback, dll
3. `Leather interior` : Menunjukkan apakah mobil memiliki interior kulit atau tidak.
4. `Fuel type` : Jenis bahan bakar yang digunakan mobil
5. `Engine volume` : Volume mesin mobil, diukur dalam liter
6. `Mileage` : Jarak tempuh mobil dalam KM
7. `Cylinders` : Jumlah silinder dalam mesin mobil.
8. `Gear box type` : Jenis kotak gigi/transmisi, seperti manual, otomatis, atau semi-otomatis.
9. `Drive wheels` : Jenis penggerak roda, seperti penggerak roda depan, belakang, atau semua roda.
10. `Doors` : Jumlah pintu pada mobil.
11. `Wheel` : Jenis roda yang digunakan, bisa juga merujuk pada *steering wheel* (kiri atau kanan).
12. `Color` : Warna eksterior mobil.
13. `Airbags` : Jumlah kantung udara keselamatan yang tersedia di mobil.

# **3. *Data Understanding***

## 3.1 *Exploratory Data Analysis* (EDA)

Exploratory Data Analysis (EDA) adalah proses investigasi awal pada data untuk mengidentifikasi pola, menemukan anomali, menguji hipotesis, dan memeriksa asumsi dengan menggunakan statistik ringkasan dan representasi grafis.

### 3.1.1 Deskripsi Variabel

Melakukan pengecekan informasi dari *dataframe* `car`
"""

car.info()

"""Terdapat 2 atribut dengan tipe data `int64`, 3 atribut dengan tipe data `float64` dan 8 atribut dengan tipe data `object`

### 3.1.2 Deskripsi Statistik
"""

car.describe()

"""Melihat deskripsi statistik dari *dataframe* `car` yaitu,
1.   `count` : Jumlah data
2.   `mean` : Rata-rata
3.   `std` : Standar deviasi/simpangan baku
4.   `min` : Nilai minimum
5.   `25%` : Kuartil bawah/Q1
6.   `50%` : Kuartil tengah/Q2/median
7.   `75%` : Kuartil atas/Q3
8.   `max` : Nilai maksimum

### 3.1.3 Menangani Missing Value
"""

pr =  (car['Price']         == 0).sum()
ev =  (car['Engine volume'] == 0).sum()
ml =  (car['Mileage']       == 0).sum()
cl =  (car['Cylinders']     == 0).sum()
ab =  (car['Airbags']       == 0).sum()

print("Nilai 0 di kolom price ada: ", pr)
print("Nilai 0 di kolom engine volume ada: ", ev)
print("Nilai 0 di kolom mileage ada: ", ml)
print("Nilai 0 di kolom cylinders ada: ", cl)
print("Nilai 0 di kolom airbags ada: ", ab)

"""Ada **2405 kolom** *airbags*, **10 kolom** *engine volume*, dan **721 kolom** *mileage* yang tidak diketahui. Oleh karena itu, data-data yang tidak diketahui akan dihilangkan dari *dataset*."""

car = car.loc[(car[['Engine volume', 'Mileage', 'Airbags']]!=0).all(axis=1)]

car.shape

"""Mengecek ukuran data untuk memastikan data sudah dihilangkan"""

car.head()



"""### 3.1.4 Menangani *Outliers*

Untuk memeriksa keberadaan data yang menyimpang atau *outliers* dalam *dataframe* `car` dapat menggunakan visualisasi data berupa [`boxplot`](https://seaborn.pydata.org/generated/seaborn.boxplot.html) yang dibantu oleh *library* [`seaborn`](https://seaborn.pydata.org/). *Outliers* adalah nilai-nilai yang sangat berbeda dari sebagian besar data dan bisa mempengaruhi hasil analisis secara keseluruhan. Visualisasi dengan `boxplot` memungkinkan kita untuk mengidentifikasi dan mengevaluasi *outliers* ini secara efektif.
"""

fig, axes = plt.subplots(3, 2, figsize=(14, 12))
sns.boxplot(ax=axes[0,0], x=car['Price'])
sns.boxplot(ax=axes[0,1], x=car['Engine volume'])
sns.boxplot(ax=axes[1,0], x=car['Mileage'])
sns.boxplot(ax=axes[1,1], x=car['Cylinders'])
sns.boxplot(ax=axes[2,0], x=car['Airbags'])

"""Dari diagram boxplot yang ditampilkan, terlihat bahwa pada variabel numerik yang menunjukkan adanya nilai-nilai *outlier*, yaitu data yang jauh berbeda dari nilai-nilai lainnya dalam kumpulan data tersebut.

Untuk mengidentifikasi dan menangani *outliers*, pendekatan yang digunakan adalah metode IQR, atau *Inter Quartile Range*.

$$ IQR = Q3 - Q1 $$

Selanjutnya, batas bawah dan batas atas ditetapkan untuk mengelilingi *outliers*.

$$ \text{Batas Bawah} = Q1 - 1.5 \times IQR $$
$$ \text{Batas Atas} = Q3 + 1.5 \times IQR $$

Metode ini memungkinkan identifikasi nilai yang berada di luar jangkauan normal data.
"""

Q1 = car.quantile(0.25)
Q3 = car.quantile(0.75)
IQR = Q3 - Q1
car = car[~((car < (Q1 - 1.5*IQR)) | (car > (Q3 + 1.5*IQR))).any(axis=1)]

"""Cek ukuran dataset setelah drop outliers"""

car.shape

"""Diperoleh data yang telah dibersihkan sebanyak 11288 sampel."""

fig, axes = plt.subplots(3, 2, figsize=(14, 12))
sns.boxplot(ax=axes[0,0], x=car['Price'])
sns.boxplot(ax=axes[0,1], x=car['Engine volume'])
sns.boxplot(ax=axes[1,0], x=car['Mileage'])
sns.boxplot(ax=axes[1,1], x=car['Cylinders'])
sns.boxplot(ax=axes[2,0], x=car['Airbags'])

"""Setelah membersihkan *outliers* dengan metode IQR, atau *Inter Quartile Range*, terlihat bahwa jumlah *outliers* pada boxplot telah menurun. Walaupun masih terdapat *outliers* pada variabel `price`, `engine volume`, dan `mileage`, nilai-nilai tersebut masih berada dalam rentang yang dianggap aman.

### 3.1.5 *Univariate Analysis*

Melaksanakan analisis data *univariate* terhadap variabel-variabel.

Membagi fitur pada dataset menjadi dua bagian
"""

car

numerical_features = ['Price', 'Engine volume', 'Mileage', 'Cylinders', 'Airbags']
categorical_features = ['Category', 'Leather interior', 'Fuel type', 'Gear box type', 'Drive wheels', 'Doors', 'Wheel', 'Color']

"""***Categorical Features***"""

feature = categorical_features[0]
count = car[feature].value_counts()
percent = 100*car[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Mayoritas mobil yang ada di pasar bertipe sedan"""

feature = categorical_features[1]
count = car[feature].value_counts()
percent = 100*car[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Lebih dari **50%** mobil memiliki interior terbuat dari kulit"""

feature = categorical_features[2]
count = car[feature].value_counts()
percent = 100*car[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Mayoritas mobil berbahan bakar petrol"""

feature = categorical_features[3]
count = car[feature].value_counts()
percent = 100*car[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Mobil matic lebih sering dijumpai di pasar"""

feature = categorical_features[4]
count = car[feature].value_counts()
percent = 100*car[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Mobil dengan penggerak di depan lebih banyak"""

feature = categorical_features[5]
count = car[feature].value_counts()
percent = 100*car[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Mobil dengan 4 pintu lebih banyak"""

feature = categorical_features[6]
count = car[feature].value_counts()
percent = 100*car[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Lebih banyak mobil dengan posisi stir di kiri"""

feature = categorical_features[7]
count = car[feature].value_counts()
percent = 100*car[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Warna putih, silver, dan hitam mendominasi warna mobil di pasar

***Numerical Features***

Melihat histogram masing-masing fitur
"""

car.hist(bins=50, figsize=(14,12))
plt.show()

"""Informasi yang dapat diketahui dari histogram di atas
*   Harga pasaran mobil berada di **<$1000**
*   Volume mesin kendaraan mobil umumnya 2 liter
*   Kendaraan bekas pakai mendominasi pasar mobil
*   Hampir semua mobil memiliki 4 silinder
*   Mayoritas jumlah *airbags* dalam mobil adalah 4

### 3.1.6 *Multivariate Analysis*

Melaksanakan analisis data *multivariate* terhadap variabel-variabel.

***Categorical Features***

Mengecek harga kendaraan terhadap masing-masing fitur
"""

cat_features = car.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="Price", kind="bar", dodge=False, height = 4, aspect = 4,  data=car, palette="Set3")
  plt.title("Rata-rata harga mobil relatif terhadap - {}".format(col))

"""Informasi yang bisa didapatkan dari histogram di atas
*   Mobil bertipe Jeep dan Universal memiliki harga yang tertinggi dibandingkan dengan mobil lainnya
*   Mobil dengan interior kulit memiliki harga yang lebih mahal
*   Mobil dengan bahan bakar Diesel dan *Plug-in Hybrid* memiliki harga tertinggi dan sangat jauh gap harganya dengan mobil berbahan bakar CNG
*   Harga mobil yang *Gear box*-nya bertipe Tiptronic paling tinggi
*   Tidak ada perbedaan harga mobil berdasarkan roda penggeraknya
*   Mobil dengan pintu 2 memiliki harga yang jauh dangan pintu 4 dan pintu >5
*   Mobil stri kiri memiliki harga yang lebih mahal dibandingkan mobil stir kanan
*   Harga mobil berdasarkan warna memiliki banyak variasi. Mobil dengan warna *pink, purple*, dan *green* memiliki harga di bawah rata-rata

***Numerical Features***

Menggambarkan distribusi data untuk variabel numerik dalam *dataframe* `epower` menggunakan visualisasi. Ini dilakukan dengan memanfaatkan fungsi `pairplot` dari *library* `seaborn`, dengan menetapkan `diag_kind` ke `kde` untuk mengestimasi dan memvisualisasikan distribusi probabilitas dari setiap variabel numerik.
"""

sns.pairplot(car, diag_kind = 'kde')

"""### 3.1.7 *Correlation Matrix* menggunakan *Heatmap*

Mengkaji hubungan antara variabel numerik dengan memvisualisasikan matriks korelasi melalui diagram *heatmap*.
"""

#mengevaluasi skor korelasi
fig = plt.figure(figsize=(10, 8))
corr_matrix = car.corr().round(2)

# Membuat heatmap untuk matriks korelasi
heatmap = sns.heatmap(
    corr_matrix,
    vmin=-1,
    vmax=1,
    cmap='coolwarm',
    annot=True,
    linewidths=0.5
)

heatmap.set_title('Matriks Korelasi untuk Fitur Numerik', fontsize=20)

"""Diagram *heatmap* yang ditampilkan memiliki angka dari -0.25 hingga 1, yang mengindikasikan tingkat korelasi antara variabel numerik dengan cara berikut:
- Nilai yang mendekati 1 menandakan adanya korelasi positif yang kuat antara dua variabel, di mana keduanya cenderung meningkat secara bersamaan.
- Nilai yang mendekati 0 menunjukkan bahwa tidak ada korelasi yang signifikan antara dua variabel.
- Nilai yang mendekati -1 menunjukkan korelasi negatif yang kuat, di mana satu variabel cenderung meningkat sementara yang lainnya menurun.

### 3.1.8 Analisis Korelasi Antar Fitur

Fitur `Price` memiliki korelasi yang cukup kuat dengan `Engine Volume`.

Sehingga, fitur `Mileage`, `Cylinders`, dan `Airbags`yang memiliki korelasi rendah dapat dilakukan *drop* (menghapus) untuk menghilangkan fitur-fitur tersebut.
"""

car.drop(['Mileage'],   inplace=True, axis=1)
car.drop(['Cylinders'], inplace=True, axis=1)
car.drop(['Airbags'],   inplace=True, axis=1)

car

"""# **4. *Data Preparation***

## 4.1 Encoding Fitur Kategori

Dalam proses pengkodean untuk variabel kategori, teknik yang sering digunakan adalah [*`one-hot-encoding`*](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). Fungsi ini tersedia dalam library [*`scikit-learn`*](https://scikit-learn.org/), yang memungkinkan transformasi variabel kategori menjadi fitur-fitur baru yang dapat merepresentasikan informasi kategorikal dengan tepat.
"""

#One-hot-encoding
car = pd.concat([car, pd.get_dummies(car['Category'], prefix='Category')],axis=1)
car = pd.concat([car, pd.get_dummies(car['Leather interior'], prefix='Leather interior')],axis=1)
car = pd.concat([car, pd.get_dummies(car['Fuel type'], prefix='Fuel type')],axis=1)
car = pd.concat([car, pd.get_dummies(car['Gear box type'], prefix='Gear box type')],axis=1)
car = pd.concat([car, pd.get_dummies(car['Drive wheels'], prefix='Drive wheels')],axis=1)
car = pd.concat([car, pd.get_dummies(car['Doors'], prefix='Doors')],axis=1)
car = pd.concat([car, pd.get_dummies(car['Wheel'], prefix='Wheel')],axis=1)
car = pd.concat([car, pd.get_dummies(car['Color'], prefix='Color')],axis=1)
car.drop(['Category','Leather interior','Fuel type', 'Gear box type', 'Drive wheels', 'Doors', 'Wheel', 'Color'], axis=1, inplace=True)

car

"""## 4.2 Train-Test-Split

Membagi dataset menjadi data latih (*train*) dan data uji (*test*)
"""

X = car.drop(["Price"],axis =1)
y = car["Price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## 4.3 Standarisasi pada Fitur Numerik

Melakukan standarisasi nilai pada fitur numerik dengan menggunakan `StandardScaler` dari *library* `scikit-learn`. Proses standarisasi ini bertujuan untuk mencegah terjadinya penyimpangan nilai data yang cukup besar.
"""

numericalFeatures = ['Engine volume']

scaler = StandardScaler()
scaler.fit(X_train[numericalFeatures])
X_train[numericalFeatures] = scaler.transform(X_train.loc[:, numericalFeatures])
X_train[numericalFeatures].head()

"""## 4.4 Reduksi Dimensi

Reduksi dimensi adalah metode yang digunakan untuk mengurangi jumlah variabel dalam data sambil memastikan informasi penting tetap terjaga. Salah satu metode reduksi dimensi yang sering digunakan adalah *Principal Component Analysis*, atau PCA. Teknik ini mengurangi dimensi data dengan mengubahnya dari ruang berdimensi n menjadi ruang berdimensi m yang lebih rendah, di mana m lebih kecil dari n, tanpa kehilangan esensi data tersebut.
"""

sns.pairplot(car[['Price','Engine volume']], plot_kws={"s": 3});

"""Aplikasikan [*`class PCA`*](https://scikit--learn-org.translate.goog/stable/modules/generated/sklearn.decomposition.PCA.html?_x_tr_sl=en&_x_tr_tl=id&_x_tr_hl=id&_x_tr_pto=tc) dari library *`scikit learn`*"""

pca = PCA(n_components=2, random_state=123)
pca.fit(car[['Price','Engine volume']])
princ_comp = pca.transform(car[['Price','Engine volume']])

"""Mengetahui proporsi informasi dari kedua komponen"""

#Proporsi informasi
pca.explained_variance_ratio_.round(3)

car

"""# **5. *Model Development***

## 5.1 *Model Preparation*

Menyiapkan *dataframe* untuk analisis model menggunakan `index` yang terdiri dari `train_mse` dan `test_mse`, serta `columns` yang mencakup algoritma prediksi seperti [`K-Nearest Neighbor (KNN)`](https://www.geeksforgeeks.org/k-nearest-neighbours/), [`Random Forest`](https://www.ibm.com/topics/random-forest#:~:text=Random%20forest%20is%20a%20commonly,Decision%20trees), dan [`Adaptive Boosting (AdaBoost)`](https://www.analyticsvidhya.com/blog/2021/09/adaboost-algorithm-a-complete-guide-for-beginners/#:~:text=AdaBoost%20algorithm%2C%20short%20for%20Adaptive,assigned%20to%20incorrectly%20classified%20instances.).
"""

models = pd.DataFrame(
    index=['train_mse', 'test_mse'],
    columns=['KNN', 'RandomForest', 'Boosting']
    )

"""## 5.2 *K-Nearest Neighbor (KNN) Algorithm*

*Algoritma K-Nearest Neighbor (KNN)* beroperasi berdasarkan prinsip kesamaan antara sampel data uji dan data latih, dengan membandingkan fitur-fitur yang ada. KNN melakukan ini dengan menghitung jarak antara sampel uji dengan setiap sampel latih dan memilih sejumlah tetangga terdekat yang ditentukan oleh nilai k, yang merupakan bilangan bulat positif.
"""

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""## *5.3 Random Forest Algorithm*

*Random Forest* adalah sebuah algoritma pembelajaran terawasi (*supervised learning*) yang berada dalam kategori pembelajaran ansambel (*ensemble group learning*). Ini berarti bahwa *Random Forest* membangun sejumlah model prediktif yang bekerja secara mandiri. Hasil dari masing-masing model ini kemudian dikombinasikan untuk menghasilkan prediksi akhir yang lebih kuat dan akurat.
"""

RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""## 5.4 *Adaptive Boosting (AdaBoost) Algorithm*

*Adaptive Boosting*, atau AdaBoost, adalah teknik yang secara bertahap melatih model dalam serangkaian iterasi. Setiap data dalam set pelatihan diawali dengan bobot yang seragam, dan setelah setiap iterasi, model mengevaluasi kinerjanya. Data yang diklasifikasikan secara tidak tepat mendapatkan peningkatan bobot, memfokuskan model pada kasus yang lebih sulit di iterasi berikutnya. Proses ini berulang sampai model mencapai tingkat akurasi yang optimal.
"""

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""# **6. *Model Evaluation***

Evaluasi model regresi pada dasarnya cukup mudah dipahami. Pada intinya, sebagian besar metrik evaluasi memiliki prinsip yang serupa. Performa model dianggap baik jika prediksi yang dihasilkan dekat dengan nilai aktual. Sebaliknya, dianggap kurang baik jika jauh dari nilai aktual. Perbedaan antara nilai yang diprediksi dan nilai aktual dikenal sebagai kesalahan prediksi. Oleh karena itu, tujuan utama dari semua metrik adalah untuk mengukur dan meminimalkan kesalahan prediksi tersebut.
"""

# Terapkan normalisasi pada data numerik dalam X_test agar nilai rata-ratanya menjadi nol dan variansnya satu
X_test.loc[:, numericalFeatures] = scaler.transform(X_test[numericalFeatures])

"""Evaluasi performa tiga model pembelajaran mesin: *K-Nearest Neighbor, Random Forest*, dan *AdaBoost*, pada set data pelatihan dan pengujian dengan mengukur tingkat kesalahan ketiga algoritma tersebut melalui *Mean Squared Error* (MSE)."""

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

mse

"""Tampilkan prediksi *error* dari model *K-Nearest Neighbor, Random Forest*, dan *AdaBoost* untuk data pelatihan dan pengujian menggunakan diagram batang."""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Berdasarkan diagram yang ditampilkan, dapat diketahui:
1.   Algoritma *Random Forest* menghasilkan nilai *error* terendah.
2.   Algoritma *K-Nearest Neighbor* menunjukkan tingkat *error* yang berada di tengah-tengah dibandingkan dengan dua algoritma lain.
3.   Algoritma *Adaptive Boosting* memiliki tingkat *error* tertinggi.

Melakukan pengujian prediksi dengan menggunakan harga (*price*) dari data uji (*testing*)
"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Dapat dilihat prediksi pada model dengan algoritma *K-Nearest Neighbor* memberikan hasi yang paling mendekati dengan nilai `y_true` jika dibandingkan dengan algoritma model yang lainnya.

Nilai `y_true` sebesar **26594.0** dan nilai prediksi `*K-Nearest Neighbor*` sebesar **24513.1**.

Meskipun diagram `MSE` menunjukan *Random Forest* memiliki error paling kecil dibanding algoritma lainnya, ketika dilakukan pengujian justru *K-Nearest Neighbor* menghasilkan prediksi yang lebih mendekati `y_true`.
"""